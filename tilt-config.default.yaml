# CanopyX Tilt Configuration
# Copy this file to tilt-config.yaml and customize for your local environment
#
# This file controls which components run and their resource allocation.
# Designed to allow developers to run minimal setups on laptops while
# also supporting production-like testing when needed.

# ==============================================================================
# PROFILE SELECTION
# ==============================================================================
# Options: "minimal", "development", "production"
#
# minimal:     Only essential components (no monitoring, no canopy node)
#              Best for: Laptop development, UI work, API testing
#              Resources: ~4GB RAM, 2 CPU cores
#
# development: Full stack with minimal replicas (default)
#              Best for: Full-stack development, workflow testing
#              Resources: ~8GB RAM, 4 CPU cores
#
# production:  Production-like setup with replication and monitoring
#              Best for: Performance testing, benchmarking, demo
#              Resources: ~27GB RAM, ~11 CPU cores (fits on 16 core / 64GB machine)
#              Note: Runs multiple replicas on a single node (pod anti-affinity disabled)
#                    Perfect for single-node KIND clusters or shared dev servers
profile: development

# ==============================================================================
# MODE SELECTION
# ==============================================================================
# Options: "local", "shared"
#
# local:   Local development mode with hot reloading
#          - Next.js runs in dev mode (NODE_ENV=development)
#          - Go services use live binary sync for instant updates
#          - Indexer builds manually (on demand)
#          Best for: Individual developers working on their laptops
#
# shared:  Shared development server mode (production-like builds)
#          - Next.js runs optimized production build (NODE_ENV=production)
#          - Go services require full rebuild (no hot reload)
#          - Indexer builds automatically on code changes
#          Best for: Team dev server where multiple people connect
#
# Recommended combinations:
#   - Local laptop:      profile: development + mode: local
#   - Shared dev server: profile: development + mode: shared
mode: local

# ==============================================================================
# COMPONENT TOGGLES
# ==============================================================================
# Enable/disable OPTIONAL components to save resources
# Note: ClickHouse and Temporal are ALWAYS required and cannot be disabled
#       (they're configured via resource limits below instead)
components:
  # --- Optional Monitoring ---
  monitoring: false       # Prometheus + Grafana (adds ~1GB RAM)
                          # Enable this for: performance testing, debugging, demos
                          # Disable for: normal development, laptop environments

  # --- Optional Mock Blockchain ---
  canopy: true            # Canopy RPC Mock (lightweight mock blockchain for development)
                          # true  - Deploy canopy-rpc-mock with configurable chains
                          # false - No mock nodes (use external RPC endpoints from chains config)
                          #
                          # Benefits of mock:
                          #   - Deterministic blocks (no timing issues)
                          #   - Fast startup (~5 seconds vs minutes for real node)
                          #   - Multiple chains in single pod (~100MB RAM total)
                          #   - Perfect for rapid development and testing
                          #
                          # Configure mock chains in paths section below

  # --- Optional Services (you can disable these if not needed) ---
  admin: true             # Admin API server
                          # Disable if: only running indexer, testing without API

  controller: true        # Controller (manages indexer deployments)
                          # Disable if: running standalone indexer, testing without auto-scaling

  admin_web: true         # Next.js admin UI
                          # Disable if: only using API directly, not working on UI

# NOTE: Indexer is always required (managed by controller when enabled, or deployed manually)

# ==============================================================================
# PATHS
# ==============================================================================
# Configure paths to external repositories and mock configuration
paths:
  # Path to canopy-rpc-mock source code (if using mock blockchain)
  # The mock will only be deployed if:
  #   1. components.canopy is set to true
  #   2. This path exists and contains the canopy-rpc-mock repository
  #
  # Examples:
  #   canopy_rpc_mock_source: "../canopy-rpc-mock"     # Sibling directory (default)
  #   canopy_rpc_mock_source: "/path/to/canopy-rpc-mock"  # Absolute path
  canopy_rpc_mock_source: "../canopy-rpc-mock"

  # Mock RPC configuration (only used when components.canopy = true)
  # These settings control how many chains and blocks the mock creates
  mock_chains: 2                # Number of separate blockchain chains to mock
  mock_blocks: 100              # Number of blocks each chain will have
  mock_start_port: 60000        # Starting port for RPC servers (chain 1 on 60000, chain 2 on 60001, etc.)
  mock_start_chain_id: 5        # Starting chain ID (first chain will be ID 5, second ID 6, etc.)

# ==============================================================================
# RESOURCE LIMITS BY PROFILE
# ==============================================================================
# These settings control replica counts and resource limits
# You generally don't need to edit these unless you have specific requirements
resources:
  minimal:
    clickhouse:
      cpu_limit: "1000m"
      memory_limit: "2Gi"
      cpu_request: "500m"
      memory_request: "1Gi"

    temporal:
      history_replicas: 1
      cassandra_replicas: 1
      cassandra_heap_size: "4G"
      cassandra_memory_limit: "6G"
      elasticsearch_replicas: 1
      elasticsearch_memory_limit: "1Gi"
      elasticsearch_cpu_limit: "1000m"

    canopyx:
      admin_cpu_limit: "500m"
      admin_memory_limit: "512Mi"
      controller_cpu_limit: "500m"
      controller_memory_limit: "512Mi"
      admin_web_cpu_limit: "200m"
      admin_web_memory_limit: "512Mi"  # Higher for Next.js dev mode with hot reload

    indexer:
      min_replicas: 1
      max_replicas: 1

    monitoring:
      enabled: false  # Force disable monitoring in minimal mode
      prometheus_cpu_limit: "500m"
      prometheus_memory_limit: "512Mi"
      grafana_cpu_limit: "200m"
      grafana_memory_limit: "256Mi"

  development:
    clickhouse:
      cpu_limit: "2000m"
      memory_limit: "4Gi"
      cpu_request: "1000m"
      memory_request: "2Gi"

    temporal:
      history_replicas: 1
      cassandra_replicas: 1
      cassandra_heap_size: "8G"
      cassandra_memory_limit: "12G"
      elasticsearch_replicas: 1
      elasticsearch_memory_limit: "2Gi"
      elasticsearch_cpu_limit: "2000m"

    canopyx:
      admin_cpu_limit: "1000m"
      admin_memory_limit: "1Gi"
      controller_cpu_limit: "1000m"
      controller_memory_limit: "1Gi"
      admin_web_cpu_limit: "500m"
      admin_web_memory_limit: "512Mi"

    indexer:
      min_replicas: 1
      max_replicas: 1

    monitoring:
      prometheus:
        retention: "2d"
        scrape_interval: "15s"
        cpu_limit: "1000m"
        memory_limit: "1Gi"
      grafana:
        enabled: true
        cpu_limit: "500m"
        memory_limit: "512Mi"
      prometheus_cpu_limit: "1000m"
      prometheus_memory_limit: "1Gi"
      grafana_cpu_limit: "500m"
      grafana_memory_limit: "512Mi"

  production:
    # IMPORTANT: Optimized for single-node clusters with 16 cores / 64GB RAM
    # Target: Stay under 28GB RAM and 12 cores to leave headroom for system
    # All replicas run on same node (anti-affinity disabled)
    #
    # Estimated usage with this config:
    #   Cassandra:       3 × 3GB   = 9GB   (3 cores)
    #   Elasticsearch:   3 × 1.5GB = 4.5GB (3 cores)
    #   ClickHouse:      1 × 4GB   = 4GB   (2 cores)
    #   Temporal svcs:   3 × 1GB   = 3GB   (1.5 cores)
    #   CanopyX svcs:              = 3GB   (2 cores)
    #   Monitoring:                = 1.5GB (1 core)
    #   System overhead:           = 2GB   (1 core)
    #   --------------------------------
    #   TOTAL:                    ~27GB   ~11.5 cores

    clickhouse:
      cpu_limit: "2000m"
      memory_limit: "4Gi"
      cpu_request: "1000m"
      memory_request: "2Gi"

    temporal:
      history_replicas: 3
      cassandra_replicas: 3
      cassandra_heap_size: "2G"        # Reduced from 16G
      cassandra_memory_limit: "3G"     # Reduced from 24G (3 × 3GB = 9GB total)
      elasticsearch_replicas: 3
      elasticsearch_memory_limit: "1536Mi"  # Reduced from 4Gi (3 × 1.5GB = 4.5GB total)
      elasticsearch_cpu_limit: "1000m"       # Reduced from 4000m

    canopyx:
      admin_cpu_limit: "1000m"
      admin_memory_limit: "1Gi"
      controller_cpu_limit: "1000m"
      controller_memory_limit: "1Gi"
      admin_web_cpu_limit: "500m"
      admin_web_memory_limit: "1Gi"

    indexer:
      min_replicas: 1
      max_replicas: 1

    monitoring:
      prometheus:
        retention: "3d"              # Reduced from 7d
        scrape_interval: "15s"       # Reduced from 10s
        cpu_limit: "1000m"           # Reduced from 2000m
        memory_limit: "1Gi"          # Reduced from 2Gi
      grafana:
        enabled: true
        cpu_limit: "500m"            # Reduced from 1000m
        memory_limit: "512Mi"        # Reduced from 1Gi
      prometheus_cpu_limit: "1000m"
      prometheus_memory_limit: "1Gi"
      grafana_cpu_limit: "500m"
      grafana_memory_limit: "512Mi"

# ==============================================================================
# PORT FORWARDING
# ==============================================================================
# Configure local ports for accessing services
# Change these if you have conflicts with other services
ports:
  # ClickHouse
  clickhouse_web: 8081       # HyperDX web UI
  clickhouse_server: 8123    # ClickHouse HTTP
  clickhouse_native: 9000    # ClickHouse native protocol

  # Temporal
  temporal_web: 8080         # Temporal web UI
  temporal_frontend: 7233    # Temporal gRPC
  temporal_worker: 7239      # Temporal worker

  # Monitoring (only if components.monitoring = true)
  prometheus: 9090           # Prometheus UI
  grafana: 3100              # Grafana UI

  # CanopyX Services
  admin: 3000                # Admin API
  admin_web: 3003            # Admin web UI

  # Canopy RPC Mock (only if components.canopy = true)
  # Ports are auto-generated based on mock_chains and mock_start_port in paths config
  # Default with 2 chains starting at port 60000:
  #   canopy_mock_chain_1: 60000  # Chain ID 5
  #   canopy_mock_chain_2: 60001  # Chain ID 6
  # Customize these if you have port conflicts:
  canopy_mock_chain_1: 60000    # First mock chain RPC
  canopy_mock_chain_2: 60001    # Second mock chain RPC

# ==============================================================================
# MONITORING CONFIGURATION
# ==============================================================================
# Only applies if components.monitoring = true
monitoring:
  # Dashboards to load into Grafana
  # These files should exist in deploy/k8s/grafana/base/dashboards/
  dashboards:
    - deploy/k8s/grafana/base/dashboards/canopyx-overview.json
    # Add more dashboards here as you create them:
    # - deploy/k8s/grafana/base/dashboards/temporal-detailed.json
    # - deploy/k8s/grafana/base/dashboards/clickhouse-performance.json

  # Prometheus scrape targets
  # Add custom scrape configs if you have additional services
  extra_scrape_configs: []
    # Example:
    # - job_name: 'my-custom-service'
    #   static_configs:
    #     - targets: ['my-service:9090']

# ==============================================================================
# CHAIN REGISTRATION
# ==============================================================================
# Register external blockchain networks to index.
# Only rpc_endpoints is required - all other fields have sensible defaults.
chains: []
  # Minimal example (only required field):
  # - rpc_endpoints: ["https://node1.example.com/rpc"]

  # Full example with all optional fields:
  # - rpc_endpoints: ["https://node1.example.com/rpc", "https://node2.example.com/rpc"]
  #   chain_id: 1000                    # OPTIONAL: Auto-detected from RPC if not provided
  #   chain_name: "My Custom Chain"     # OPTIONAL: Defaults to "Chain {id}"
  #   image: "canopynetwork/canopyx-indexer:latest"  # OPTIONAL: Default shown
  #   min_replicas: 1                   # OPTIONAL: Minimum Kubernetes replicas (default: 1)
  #   max_replicas: 1                   # OPTIONAL: Maximum Kubernetes replicas (default: 1)
  #   reindex_min_replicas: 1           # OPTIONAL: Minimum replicas during reindex (default: 1)
  #   reindex_max_replicas: 1           # OPTIONAL: Maximum replicas during reindex (default: 1)
  #   notes: "Production mainnet"       # OPTIONAL: Human-readable notes (default: "")
  #   paused: false                     # OPTIONAL: Start paused instead of indexing (default: false)

  # Real-world example:
  # - rpc_endpoints: ["https://node1.canopy.us.nodefleet.net/rpc"]
  #   chain_name: "Canopy Mainnet"
  #   min_replicas: 2
  #   max_replicas: 3

# ==============================================================================
# ENVIRONMENT VARIABLE OVERRIDES
# ==============================================================================
# Override default environment variables for admin, controller, and indexer
# All variables are commented out and show their default values from code
# Uncomment and modify to override defaults for local development

env:
  # =============================================================================
  # ADMIN SERVER
  # =============================================================================
  admin:
    # ----- Server Configuration -----
    # ADDR: ":3000"                          # Server listen address (default: ":3000")

    # ----- Authentication & Security -----
    # ADMIN_TOKEN: "devtoken"                # Admin API authentication token (default: "devtoken")
    # ADMIN_USER: "admin"                    # Default admin username (default: "admin")
    # ADMIN_PASSWORD: "admin"                # Default admin password (default: "admin")
    # ADMIN_USERS: ""                        # JSON array of additional users (default: "")
    # SESSION_SECRET: "change-me-please"     # JWT session secret (default: "change-me-please")
    # ENVIRONMENT: ""                        # Environment: "production" or "" (default: "")

    # ----- Database Configuration -----
    # INDEXER_DB: "canopyx_indexer"          # Indexer database name (default: "canopyx_indexer")
    # CROSSCHAIN_DB: "canopyx_cross_chain"   # Cross-chain database name (default: "canopyx_cross_chain")

    # ----- ClickHouse Connection -----
    # Admin calculates pool sizes deterministically: (10 activities × 2 connections) + 10 buffer = 30 connections
    # CLICKHOUSE_ADDR: "clickhouse://localhost:9000?sslmode=disable"  # Required - ClickHouse DSN
    # CLICKHOUSE_CONN_STRATEGY: "in_order"   # Connection strategy: in_order, round_robin, random (default: "in_order")
    # CLICKHOUSE_CONN_MAX_LIFETIME: "1h"     # Connection recycling interval (default: "1h")

    # ----- Temporal Configuration -----
    # TEMPORAL_HOSTPORT: "localhost:7233"    # Required - Temporal server address
    # TEMPORAL_NAMESPACE: "canopyx"          # Required - Temporal namespace

    # ----- Redis Configuration -----
    # REDIS_ENABLED: "false"                 # Enable Redis for real-time WebSocket events (default: "false")
    # REDIS_HOST: "localhost"                # Redis server host (default: "localhost")
    # REDIS_PORT: "6379"                     # Redis server port (default: "6379")
    # REDIS_PASSWORD: ""                     # Redis password (default: "")
    # REDIS_DB: "0"                          # Redis database number (default: 0)

    # ----- Logging Configuration -----
    # LOG_LEVEL: "debug"                     # Logging level: debug, info, warn, error (default: "debug")
    # LOG_ENCODING: "json"                   # Log encoding: json, console (default: "json")

  # =============================================================================
  # CONTROLLER
  # =============================================================================
  controller:
    # ----- Server Configuration -----
    # ADDR: ":3002"                          # Server listen address (default: ":3002")

    # ----- Kubernetes Configuration -----
    # K8S_NAMESPACE: "default"               # Required - Kubernetes namespace for indexer deployments
    # KUBECONFIG: ""                         # Path to kubeconfig file (default: "", uses in-cluster config)
    # PROVIDER: "k8s"                        # Provider type: k8s or fake (default: "fake" in code, "k8s" in deployment)

    # ----- Indexer Deployment Configuration -----
    # INDEXER_IMAGE: "localhost:5001/canopyx-indexer"  # Required - Indexer container image
    # INDEXER_TAG: ""                        # Image tag override (default: "", uses image tag)
    # INDEXER_REPLICAS: "1"                  # Initial replica count (default: 1)
    # INDEXER_CPU: ""                        # CPU limit per indexer pod (default: "", no override)
    # INDEXER_MEM: ""                        # Memory limit per indexer pod (default: "", no override)
    # INDEXER_PULL_POLICY: "Always"          # Image pull policy: Always, IfNotPresent, Never (default: "Always")
    # INDEXER_PULL_SECRET: ""                # Image pull secret name (default: "")

    # ----- HPA (Horizontal Pod Autoscaling) -----
    # INDEXER_ENABLE_HPA: "false"            # Enable HPA for indexer (default: false)
    # INDEXER_HPA_MIN: "1"                   # Minimum replicas for HPA (default: 1)
    # INDEXER_HPA_MAX: "5"                   # Maximum replicas for HPA (default: 5)
    # INDEXER_HPA_CPU_TARGET: "80"           # CPU target percentage for HPA (default: 80)

    # ----- Database Configuration -----
    # INDEXER_DB: "canopyx_indexer"          # Indexer database name (default: "canopyx_indexer")

    # ----- ClickHouse Connection -----
    # Controller calculates pool sizes deterministically: (5 queries × 2 connections) + 5 buffer = 15 connections
    # CLICKHOUSE_ADDR: "clickhouse://localhost:9000?sslmode=disable"  # Required - ClickHouse DSN
    # CLICKHOUSE_CONN_STRATEGY: "in_order"   # Connection strategy (default: "in_order")
    # CLICKHOUSE_CONN_MAX_LIFETIME: "1h"     # Connection recycling interval (default: "1h")

    # ----- Temporal Configuration -----
    # TEMPORAL_HOSTPORT: "localhost:7233"    # Required - Temporal server address
    # TEMPORAL_NAMESPACE: "canopyx"          # Required - Temporal namespace
    # TEMPORAL_TASK_QUEUE_PREFIX: "index:"   # Task queue prefix (default: "index:")

    # ----- Redis Configuration -----
    # REDIS_HOST: "localhost"                # Required - Redis server host
    # REDIS_PORT: "6379"                     # Required - Redis server port
    # REDIS_PASSWORD: ""                     # Redis password (default: "")
    # REDIS_DB: ""                           # Redis database number (default: "", passed to indexer)

    # ----- Parallelism Configuration (Passed to Indexer Pods) -----
    # Indexer calculates connection pool sizes and Temporal limits from these values
    # Formula: (parallel_blocks × 10 peak_concurrent_activities × 1 conn) + 20 buffer
    # Example: (5+10+10) × 10 × 1 + 20 = 270 connections per indexer replica
    # At 100 chains: 100 × 270 = 27,000 total connections to ClickHouse
    # LIVE_PARALLEL_BLOCKS: "5"              # Live indexing parallelism (default: 5)
    # HISTORICAL_PARALLEL_BLOCKS: "10"       # Historical indexing parallelism (default: 10)
    # REINDEX_PARALLEL_BLOCKS: "10"          # Reindex parallelism (default: 10)

    # ----- Scheduler Configuration (Passed to Indexer Pods) -----
    # SCHEDULER_CATCHUP_THRESHOLD: "200"     # Block lag threshold for direct scheduling (default: 200)
    # DIRECT_SCHEDULE_BATCH_SIZE: "50"       # Batch size for direct scheduling (default: 50)
    # SCHEDULER_BATCH_SIZE: "500"            # Workflows per batch (default: 500, scaled for 100+ chains)
    #                                        # With 100 chains: 100×500=50k concurrent workflows per cycle
    #                                        # Lower values reduce Temporal/Cassandra pressure
    # BLOCK_TIME_SECONDS: "20"               # Expected block time in seconds (default: 20)
    # SCHEDULER_BATCH_MAX_PARALLELISM: "0"   # Max parallel batches, 0=unlimited (default: 0)

    # ----- Logging Configuration -----
    # LOG_LEVEL: ""                          # Logging level (default: "", passed to indexer)

  # =============================================================================
  # INDEXER (Environment variables passed from controller)
  # =============================================================================
  # Note: Indexer pods receive their configuration from the controller
  # The following variables are set by controller and documented here for reference
  #
  # ----- Chain Configuration -----
  # CHAIN_ID: ""                             # Required - Chain ID to index (set by controller)
  #
  # ----- Database Configuration -----
  # INDEXER_DB: "canopyx_indexer"            # Indexer database name (default: "canopyx_indexer")
  # CROSSCHAIN_DB: "canopyx_cross_chain"     # Cross-chain database name (default: "canopyx_cross_chain")
  #
  # ----- ClickHouse Connection -----
  # Indexer calculates pool sizes deterministically based on parallelism configuration
  # Formula: (total_parallel_blocks × 10 peak_concurrent_activities × 1 conn) + 20 buffer
  # CLICKHOUSE_ADDR: ""                      # Required - ClickHouse DSN (from controller)
  # CLICKHOUSE_CONN_STRATEGY: "in_order"     # Connection strategy (default: "in_order")
  # CLICKHOUSE_CONN_MAX_LIFETIME: "1h"       # Connection recycling interval (default: "1h")
  #
  # ----- Temporal Configuration -----
  # TEMPORAL_HOSTPORT: ""                    # Required - Temporal server (from controller)
  # TEMPORAL_NAMESPACE: ""                   # Required - Temporal namespace (from controller)
  #
  # ----- Redis Configuration -----
  # REDIS_HOST: ""                           # Required - Redis server (from controller)
  # REDIS_PORT: ""                           # Required - Redis port (from controller)
  # REDIS_DB: "0"                            # Redis database number (default: 0)
  #
  # ----- Parallelism Configuration -----
  # LIVE_PARALLEL_BLOCKS: "5"                # Live indexing parallelism (default: 5)
  # HISTORICAL_PARALLEL_BLOCKS: "10"         # Historical indexing parallelism (default: 10)
  # REINDEX_PARALLEL_BLOCKS: "10"            # Reindex parallelism (default: 10)
  #
  # ----- Scheduler Configuration -----
  # SCHEDULER_CATCHUP_THRESHOLD: "200"       # Block lag threshold for direct scheduling (default: 200)
  # DIRECT_SCHEDULE_BATCH_SIZE: "50"         # Batch size for direct scheduling (default: 50)
  # SCHEDULER_BATCH_SIZE: "500"              # Workflows per batch (default: 500, scaled for 100+ chains)
  # BLOCK_TIME_SECONDS: "20"                 # Expected block time in seconds (default: 20)
  # SCHEDULER_BATCH_MAX_PARALLELISM: "0"     # Max parallel batches, 0=unlimited (default: 0)
  #
  # ----- Logging Configuration -----
  # LOG_LEVEL: "debug"                       # Logging level: debug, info, warn, error (default: "debug")
  # LOG_ENCODING: "json"                     # Log encoding: json, console (default: "json")

# ==============================================================================
# DEVELOPMENT SETTINGS
# ==============================================================================
dev:
  # Auto-rebuild on code changes
  auto_rebuild: true

  # Automatically register local mock chain(s) (if canopy is true)
  auto_register_chain: true

  # Indexer image tag
  indexer_tag: "localhost:5001/canopyx-indexer:dev"

  # Trigger mode for indexer builds
  # Options: "auto" (rebuild on changes), "manual" (rebuild on button press)
  # Note: In 'shared' mode, this is automatically set to "auto" regardless of this setting
  indexer_build_mode: "manual"

# ==============================================================================
# EXAMPLE CONFIGURATIONS
# ==============================================================================
#
# Laptop Developer (minimal resources):
#   profile: minimal
#   components:
#     monitoring: false
#     canopy: false       # Use external RPC endpoints
#
# Full-Stack Developer (normal development):
#   profile: development
#   components:
#     monitoring: false   # Enable only when debugging
#     canopy: true        # Use mock for fast iteration
#   paths:
#     mock_chains: 2      # Test with 2 chains
#
# DEX/Pools Developer:
#   profile: development
#   components:
#     monitoring: false
#     canopy: true        # Mock supports multi-chain DEX testing
#   paths:
#     mock_chains: 2      # Chain 5 and Chain 6 for cross-chain operations
#
# Performance Testing / Benchmarking:
#   profile: production
#   components:
#     monitoring: true    # MUST be enabled for benchmarking
#     canopy: false       # Use real network for accurate perf testing
#   chains:
#     - rpc_endpoints: ["https://mainnet-rpc.example.com"]
#
# Demo / Presentation:
#   profile: production
#   components:
#     monitoring: true    # Show off the dashboards!
#     canopy: true        # Quick demo with mock data
#   paths:
#     mock_chains: 3      # Show multi-chain capabilities
